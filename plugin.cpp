// plugin.cpp : Defines the entry point for the DLL application.
//

#include "stdafx.h"
#include "IPlugin.h"
#include <math.h>
#include <stdlib.h>

#include <stdio.h>
#include <iostream>//to use cout
#include "colorspace.h"
#include "pyramid.h"
#include "smallKernels.h"
////////////////////////////////////////////////////////////////////////
// A concrete plugin implementation
////////////////////////////////////////////////////////////////////////

// Photo-Reactor Plugin class

//****************************************************************************
//This code has been generated by the Mediachance photo reactor Code generator.


#define AddParameter(N,S,V,M1,M2,T,D) {strcpy (pParameters[N].m_sLabel,S);pParameters[N].m_dValue = V;pParameters[N].m_dMin = M1;pParameters[N].m_dMax = M2;pParameters[N].m_nType = T;pParameters[N].m_dSpecialValue = D;}

#define GetValue(N) (pParameters[N].m_dValue)
#define GetValueY(N) (pParameters[N].m_dSpecialValue)

#define SetValue(N,V) {pParameters[N].m_dValue = V;}

#define GetBOOLValue(N) ((BOOL)(pParameters[N].m_dValue==pParameters[N].m_dMax))



// if it is not defined, then here it is
//#define RGB(r,g,b) ((COLORREF)(((BYTE)(r)|((WORD)((BYTE)(g))<<8))|(((DWORD)(BYTE)(b))<<16)))




#define PARAM_CONTRAST	0
#define PARAM_SATURATION	1
#define PARAM_EXPOSURE	2
#define PARAM_SWITCH	3
#define PARAM_CHANNEL	4

//#define PARAM_SIGMA 5

#define NUMBER_OF_USER_PARAMS 5

class PluginTest : public IPlugin	
{
public:




	// constructor
	PluginTest()
	{



	}


		//Plugin Icon:
	//you can add your own icon by creating 160x100 png file, naming it the same as plugin dll and then placing it in the plugins folder
	//otherwise a generic icon will be used 

	//this is the title of the box in workspace. it should be short
	const char* GetTitle () const
	{
		return "Exposure Fusion";
	}
	
	// this will appear in the help pane, you can put your credits and short info
	const char* GetDescription () const
	{
		return "Exposure Fusion 3 ways see : http://photo.stackexchange.com/questions/20896/how-does-exposure-fusion-work . Scattered, Smothered, Covered";
	}

	// BASIC PARAMETERS
	// number of inputs 0,1 or 2
	int GetInputNumber ()
	{
		return 2;
	}

	// number of outputs 0 or 1
	int GetOutputNumber ()
	{
		return 1;
	}

	int GetBoxColor ()
	{
		return RGB(255,153,0);
	}

	int GetTextColor ()
	{
		return RGB(130,130,130);
	}

	// width of the box in the workspace
	// valid are between 50 and 100
	int GetBoxWidth ()
	{
		return 100;
	}

	// set the flags
	// see the interface builder
	// ex: nFlag = FLAG_FAST_PROCESS | FLAG_HELPER;

	//FLAG_NONE same as zero	Default, no other flags set
	//FLAG_UPDATE_IMMEDIATELY	It is very fast process that can update immediately. When user turns the sliders on UI the left display will update
	//							Use Update Immediately only for fast and single loop processes, for example Desaturate, Levels.
	//FLAG_HELPER				It is an helper object. Helper objects will remain visible in Devices and they can react to mouse messages. Example: Knob, Monitor, Bridge Pin
	//FLAG_BINDING				Binding object, attach to other objects and can change its binding value. It never goes to Process_Data functions.  Example: Knob, Switch, Slider
	//FLAG_DUMMY				It is only for interface but never process any data. Never goes to Process_Data functions. Example: Text note
	//FLAG_SKIPFINAL			Process data only during designing, doesn't process during final export. Example: Monitor, Vectorscope 
	//FLAG_LONGPROCESS			Process that takes > 1s to finish. Long Process will display the Progress dialog and will prevent user from changing values during the process.
	//FLAG_NEEDSIZEDATA		    Process need to know size of original image, the zoom and what part of image is visible in the preview. When set the plugin will receive SetSizeData
	//FLAG_NEEDMOUSE			Process will receive Mouse respond data from the workplace. This is only if your object is interactive, for example Knob, Slider
	
	// addition in 5/29/2013
	// very special case (BETA):
	//FLAG_GETMAINIMAGERGBA		Process_Data will always receive full Main Image as the input buffer in the UP RGBA format (! different than normal BGRA upside down buffer), 
	//							Needs GetInputNumber  = 0 as it doesn't process buffer from the input node at all. 

	int GetFlags ()
	{
		// it is fast process
		int nFlag = FLAG_NONE;

		nFlag = nFlag | FLAG_HELPER;
		//nFlag = nFlag | FLAG_LONGPROCESS;
		//nFlag = nFlag | FLAG_NEEDMOUSE;

		return nFlag;
	}


	// User Interface Build
	// there is maximum 29 Parameters

	int GetUIParameters (UIParameters* pParameters)
	{
		// label, value, min, max, type_of_control, special_value
		// use the UI builder in the software to generate this

		double contrastMax = 1.0;
		double contrastMin = 0.0001;

		double saturationMax = 1.0;
		double saturationMin = 0.0001;

		double luminosityMax = 1.0;
		double luminosityMin = 0.0001;

		double contrastValue = 0.30;
		double saturationValue = 0.20;
		double luminosityValue = 0.60;

		AddParameter( PARAM_CONTRAST ,"Contrast", contrastValue, contrastMin, contrastMax, TYPE_SLIDER, 0.0);
		AddParameter( PARAM_SATURATION ,"Saturation", saturationValue, saturationMin, saturationMax, TYPE_SLIDER, 0.0);
		AddParameter( PARAM_EXPOSURE ,"Exposure", luminosityValue, luminosityMin, luminosityMax, TYPE_SLIDER, 0.0);
	//	AddParameter( PARAM_SIGMA , "Sigma", .10, -1.0, 1.0, TYPE_SLIDER, 0.0);//AddParameter( PARAM_SIGMA , "Sigma", .2, .01, 1.0, TYPE_SLIDER, 0.0);
	//	AddParameter( PARAM_THETA , "Theta", .5, -1.0, 1.0, TYPE_SLIDER, 0.0);

		AddParameter( PARAM_SWITCH ,"Top|Bottom", 0, 0, 1, TYPE_ONEOFMANY, 0);
		AddParameter( PARAM_CHANNEL ,"Contrast|Saturation|Exposure", 0, 0, 2, TYPE_ONEOFMANY, 0);
		

		/*sprintf(sBuffer6,"contrastMin = %f\n contrastMax = %f\n saturationMin = %f\n saturationMax = %f\n luminosityMin = %f\n luminosityMax = %f\n contrastValue = %f\n saturationValue = %f\n luminosityValue = %f"
	                     ,contrastMin,       contrastMax,       saturationMin,       saturationMax,       luminosityMax,       luminosityMax,       contrastValue,       saturationValue,       luminosityValue);
		MessageBox(NULL,sBuffer6,"Values 1", MB_OK);*/


		return NUMBER_OF_USER_PARAMS;
	}
	

	// Actual processing function for 1 input
	//***************************************************************************************************
	// Both buffers are the same size
	// don't change the IN buffer or things will go bad for other objects in random fashion
	// the pBGRA_out comes already with pre-copied data from pBGRA_in
	// Note: Don't assume the nWidth and nHeight will be every run the same or that it contains the whole image!!!! 
	// This function receives buffer of the actual preview (it can be just a crop of image when zoomed in) and during the final calculation of the full buffer
	virtual void Process_Data (BYTE* pBGRA_out,BYTE* pBGRA_in, int nWidth, int nHeight, UIParameters* pParameters)
	{
		// this is just example to desaturate and to adjust the desaturation with slider
		// Get the latest parameters

		//List of Parameters		
	}

	// actual processing function for 2 inputs
	//********************************************************************************
	// all buffers are the same size
	// don't change the IN buffers or things will go bad
	// the pBGRA_out comes already with copied data from pBGRA_in1
	virtual void Process_Data2 (BYTE* pBGRA_out, BYTE* pBGRA_in1, BYTE* pBGRA_in2, int nWidth, int nHeight, UIParameters* pParameters)
	{
		
		//http://photo.stackexchange.com/questions/20896/how-does-exposure-fusion-work
		//https://github.com/Mericam/exposure-fusion/blob/master/exposure_fusion.m
		//http://onehourofdevelopment.blogspot.com/2013/04/hdr-exposure-fusion-in-c.html
		//http://pages.cs.wisc.edu/~gautam/CS766/Assignment1/Documentation.html
		/*
		The exposure fusion(fusion, or EF) process takes each individual pixel and 
		assigns a weight to it for the contrast, saturation, and luminosity of that pixel. 
		It is the software that then determines the balance of pixels in the final image. 
		Some applications refer to this decision as the selection of the "good" or "best" pixels. 
		You can tweak the settings that determine the balance in some software 
		implementations of exposure fusion software.
		*/

		double contrast = (double)GetValue(PARAM_CONTRAST);
		double saturation = (double) GetValue(PARAM_SATURATION);
		double exposure = (double) GetValue(PARAM_EXPOSURE);
		
		int topBottom = GetValue(PARAM_SWITCH);
		int channel = GetValue(PARAM_CHANNEL);

		//this takes your 3 variables and adjust all of them so they maintain the ratios yet do not exceed 1
		double* triValue=new double[4];		
		triValue[0] = contrast;
		triValue[1] = saturation;
		triValue[2] = exposure;
		adjustTo1Weber3(triValue);
		contrast = triValue[0];
		saturation = triValue[1];
		exposure = triValue[2];
		delete [] triValue;
		//this takes your 4 variables and adjust all of them so they maintain the ratios yet do not exceed 1

		/*char sBuffer6[400];
		sprintf(sBuffer6,"contrast = %f\n saturation = %f\n luminosity = %f\n\n totalValue = %f"
			             ,contrast,       saturation,       luminosity,         totalValue);
		MessageBox(NULL,sBuffer6,"Values", MB_OK);*/



		// Enfuse uses three different criteria to judge the quality of a pixel: 
		// Exposure, saturation, and contrast. 
		// The exposure criteria favors pixels with luminance close to the middle of the range. 
		// These pixels are considered better-exposed than those with high or low luminance levels.		
		// The saturation criteria favors highly-saturated pixels. 
		// The contrast criteria favors high-contrast pixels. 
		// The local gray or color value standard deviation is used as a contrast measure. 
		// The Mertens-Kautz-Van Reeth paper suggest using a Laplacian filter, 
		// but the standard deviation produces much better results for differently-focused images.



		// for this plugin we will use 3 different categories.
		// Exposure, saturation, and contrast.
		// The exposure criteria favors pixels with luminance close to the middle of the range. 
		// These pixels are considered better-exposed than those with high or low luminance levels.		
		// The saturation criteria favors highly-saturated pixels.
		// the edges criteria favors high contrasting edges by use of a laplacian filter
		// The contrast criteria favors high-contrast pixels. 
		
		double colorDepth = 255.0f;

		float* inputImage1=new float[nWidth * nHeight * 4];
		float* inputImage2=new float[nWidth * nHeight * 4];
		initalizeArrayNeutralGrey(inputImage1, nWidth, nHeight);
		initalizeArrayNeutralGrey(inputImage2, nWidth, nHeight);

		//used to create alpha masks for weighted functions
		float* fusionImage1=new float[nWidth * nHeight * 4];
		float* fusionImage2=new float[nWidth * nHeight * 4];
		initalizeArrayNeutralGrey(fusionImage1, nWidth, nHeight);
		initalizeArrayNeutralGrey(fusionImage2, nWidth, nHeight);
		

		//reads in images
		for (int x = 0; x < nWidth; x++)		
		{
			for (int y = 0; y < nHeight; y++)
			{
				int nIdx = x * 4 + y * 4 * nWidth;
				
				//read in image 1
				float red1   = float(pBGRA_in1[nIdx + CHANNEL_R]) / colorDepth;
				float green1 = float(pBGRA_in1[nIdx + CHANNEL_G]) / colorDepth;
				float blue1  = float(pBGRA_in1[nIdx + CHANNEL_B]) / colorDepth;

				//read in image 2
				float red2   = float(pBGRA_in2[nIdx + CHANNEL_R]) / colorDepth;
				float green2 = float(pBGRA_in2[nIdx + CHANNEL_G]) / colorDepth;
				float blue2  = float(pBGRA_in2[nIdx + CHANNEL_B]) / colorDepth;
				
				
				//read in image 1
				/*
				float red1   = float(pBGRA_in1[nIdx + CHANNEL_R]);
				float green1 = float(pBGRA_in1[nIdx + CHANNEL_G]);
				float blue1  = float(pBGRA_in1[nIdx + CHANNEL_B]);

				//read in image 2
				float red2   = float(pBGRA_in2[nIdx + CHANNEL_R]);
				float green2 = float(pBGRA_in2[nIdx + CHANNEL_G]);
				float blue2  = float(pBGRA_in2[nIdx + CHANNEL_B]);
				*/

				inputImage1[nIdx + CHANNEL_R] = red1;
				inputImage1[nIdx + CHANNEL_G] = green1;
				inputImage1[nIdx + CHANNEL_B] = blue1;

				inputImage2[nIdx + CHANNEL_R] = red2;
				inputImage2[nIdx + CHANNEL_G] = green2;
				inputImage2[nIdx + CHANNEL_B] = blue2;
			}
		}

		//for contrast we run laplacian filter and pixel by pixel choose which is the darkest pixel, which is the pixel with the most contrast

		//in order for the 3x3 kernel to read the edges properly, we need to have an array that is
		//slightly larger than the original array by adding 1 pixel to the top, bottom, left and right
		int widthPlus = nWidth + 2;
		int heightPlus = nHeight + 2;

		//this array is used for contrast, delete it aterwards to free memory
		float* luminance1 = new float[widthPlus * heightPlus * 4];
		float* luminance2 = new float[widthPlus * heightPlus * 4];
		initalizeArrayNeutralGrey(luminance2, widthPlus, heightPlus);
		initalizeArrayNeutralGrey(luminance1, widthPlus, heightPlus);

		// measure edge contrast  OUTPUT TO RED
		{
			//moves image to center in larger array and reflect edges so we can run laplacian on entire image
			shiftReflectOddKernel(inputImage1, nWidth, nHeight, luminance1, widthPlus, heightPlus, 3);
			shiftReflectOddKernel(inputImage2, nWidth, nHeight, luminance2, widthPlus, heightPlus, 3);

			//run laplacian filter
			LaPlacian3x3FourNeighbors(luminance1,widthPlus,heightPlus);
			LaPlacian3x3FourNeighbors(luminance2,widthPlus,heightPlus);

			//convert to monochrome
			monochromeConversionRec709Luminance(luminance1,widthPlus,heightPlus);
			monochromeConversionRec709Luminance(luminance2,widthPlus,heightPlus);

			//array to store filtered image
			float* edgesArrayImage1 = new float[nWidth * nHeight * 4];
			float* edgesArrayImage2 = new float[nWidth * nHeight * 4];

			// remove reflected edges and move to new array
			stripReflectedOddKernelAndMove(edgesArrayImage1,nWidth, nHeight,luminance1, widthPlus, heightPlus,3);
			stripReflectedOddKernelAndMove(edgesArrayImage2,nWidth, nHeight,luminance2, widthPlus, heightPlus,3);



			//   ***IMPORTANT***
			//   *** BUILD AN ALPHA MASK WITH THE RESULTS, place in Red Channel
			for (int x = 0; x < nWidth; x++)
			{
				for (int y = 0; y < nHeight; y++)
				{				
					int nIdx = x * 4 + y * 4 * nWidth;

					float red1 = edgesArrayImage1[nIdx + CHANNEL_R];
					float red2 = edgesArrayImage2[nIdx + CHANNEL_R];

					fusionImage1 [nIdx + CHANNEL_R] = red1;
					fusionImage2 [nIdx + CHANNEL_R] = red2;
				}
			}

			/*
			// test			
			for (int x = 0; x < nWidth; x++)
			{
				for (int y = 0; y < nHeight; y++)
				{				
					int nIdx = x * 4 + y * 4 * nWidth;

					float enhancedRed = 0;
					float enhancedGreen = 0;
					float enhancedBlue = 0;

					if (topBottom == 0)
					{
						enhancedRed = fusionImage1[nIdx + CHANNEL_R];
						enhancedGreen = fusionImage1[nIdx + CHANNEL_R];
						enhancedBlue = fusionImage1[nIdx + CHANNEL_R];
					}

					if (topBottom == 1)
					{
						enhancedRed = fusionImage2[nIdx + CHANNEL_R];
						enhancedGreen = fusionImage2[nIdx + CHANNEL_R];
						enhancedBlue = fusionImage2[nIdx + CHANNEL_R];
					}
					pBGRA_out[nIdx + CHANNEL_R] = CLAMP255(enhancedRed * colorDepth);
					pBGRA_out[nIdx + CHANNEL_G] = CLAMP255(enhancedGreen * colorDepth);
					pBGRA_out[nIdx + CHANNEL_B] = CLAMP255(enhancedBlue * colorDepth);
				}
			}
			*/

			delete [] edgesArrayImage1;
			delete [] edgesArrayImage2;

		}//end measure edge contrast

		//clean up memory
		delete [] luminance1;
		delete [] luminance2;

		// measure saturation  OUTPUT TO GREEN
		{
			//convert to the HSL colorspace to measure saturation
			RGBtoHSV(inputImage1,nWidth,nHeight);
			RGBtoHSV(inputImage2,nWidth,nHeight);
			//Saturation is found in the green channel

			//   ***IMPORTANT***
			//   *** BUILD AN ALPHA MASK WITH THE RESULTS, output to Green channel
			//create alpha mask
			for (int x = 0; x < nWidth; x++)
			{
				for (int y = 0; y < nHeight; y++)
				{				
					int nIdx = x * 4 + y * 4 * nWidth;

					float green1 = inputImage1[nIdx + CHANNEL_G];
					float green2 = inputImage2[nIdx + CHANNEL_G];

					fusionImage1 [nIdx + CHANNEL_G] = green1;
					fusionImage2 [nIdx + CHANNEL_G] = green2;
				}
			}

			//convert images back to sRGB
			HSVtoRGB(inputImage1,nWidth,nHeight);
			HSVtoRGB(inputImage2,nWidth,nHeight);
		}// end measure saturation


		float* luma1 = new float[nWidth * nHeight * 4];
		float* luma2 = new float[nWidth * nHeight * 4];

		copyImage(inputImage1,nWidth,nHeight,luma1,nWidth,nHeight);
		copyImage(inputImage2,nWidth,nHeight,luma2,nWidth,nHeight);


		// measure Exposure  OUTPUT TO BLUE
		{
			float sigma = .2;
			// AddParameter( PARAM_SIGMA , "Sigma", .03, .001, 1.0, TYPE_SLIDER, 0.0);
			// AddParameter( PARAM_THETA , "Theta", .5, .001, 1.0, TYPE_SLIDER, 0.0);

			//monochromeConversionRec709Luminance(luma1,nWidth,nHeight);
			//monochromeConversionRec709Luminance(luma2,nWidth,nHeight);
			//we are using RGB as equals, you can also try using luminance as guide

			for (int x = 0; x < nWidth; x++)
			{
				for (int y = 0; y < nHeight; y++)
				{				
					int nIdx = x * 4 + y * 4 * nWidth;

					float red1 = luma1[nIdx + CHANNEL_R];
					float green1 = luma1[nIdx + CHANNEL_G];
					float blue1 = luma1[nIdx + CHANNEL_B];

					float red2 = luma2[nIdx + CHANNEL_R];
					float green2 = luma2[nIdx + CHANNEL_G];
					float blue2 = luma2[nIdx + CHANNEL_B];

					/*
					//GOOD STARTING POINT
					float redExposure1 = exp(-(red1 - .5 ) * (red1 - .5 ) / sigma);
					float greenExposure1 = exp(-(green1 - .5 ) * (green1 - .5 ) / sigma);
					float blueExposure1 = exp(-(blue1 - .5 ) * (blue1 - .5 ) / sigma);
					float redExposure2 = exp(-(red2 - .5 ) * (red2 - .5 ) / sigma);
					float greenExposure2 = exp(-(green2 - .5 ) * (green2 - .5 ) / sigma);
					float blueExposure2 = exp(-(blue2 - .5 ) * (blue2 - .5 ) / sigma);

					//try 2
					float redExposure1 = exp(-(red1 - theta ) * (red1 - theta ) / sigma);
					float greenExposure1 = exp(-(green1 - theta ) * (green1 - theta ) / sigma);
					float blueExposure1 = exp(-(blue1 - theta ) * (blue1 - theta ) / sigma);
					float redExposure2 = exp(-(red2 - theta ) * (red2 - theta ) / sigma);
					float greenExposure2 = exp(-(green2 - theta ) * (green2 - theta ) / sigma);
					float blueExposure2 = exp(-(blue2 - theta ) * (blue2 - theta ) / sigma);

					//try 3
					//float redExposure1 = exp((-(red1 - theta ) / sigma) * (red1 - theta ) / sigma);
					//float greenExposure1 = exp((-(green1 - theta ) / sigma) * (green1 - theta ) / sigma);
					//float blueExposure1 = exp((-(blue1 - theta ) / sigma) * (blue1 - theta ) / sigma);
					//float redExposure2 = exp((-(red2 - theta ) / sigma) * (red2 - theta ) / sigma);
					//float greenExposure2 = exp((-(green2 - theta ) / sigma) * (green2 - theta ) / sigma);
					//float blueExposure2 = exp((-(blue2 - theta ) / sigma) * (blue2 - theta ) / sigma);
					*/

					//well exposed measurement
					float redExposure1 = exp(-0.5 * pow((red1 ) - 0.5,2) / (sigma * sigma));
					float greenExposure1 = exp(-0.5 * pow((green1 ) - 0.5,2) / (sigma * sigma));
					float blueExposure1 = exp(-0.5 * pow((blue1 ) - 0.5,2) / (sigma * sigma));

					float redExposure2 = exp(-0.5 * pow((red2 ) - 0.5,2) / (sigma * sigma));
					float greenExposure2 = exp(-0.5 * pow((green2 ) - 0.5,2) / (sigma * sigma));
					float blueExposure2 = exp(-0.5 * pow((blue2 ) - 0.5,2) / (sigma * sigma));
					//well exposed measurement



					float red11 = max(0, min(redExposure1, 1.0));
					float green11 = max(0, min(greenExposure1, 1.0));
					float blue11 = max(0, min(blueExposure1, 1.0));

					float red22 = max(0, min(redExposure2, 1.0));
					float green22 = max(0, min(greenExposure2, 1.0));
					float blue22 = max(0, min(blueExposure2, 1.0));

					//   ***IMPORTANT***
					//   *** BUILD AN ALPHA MASK WITH THE RESULTS, output to Green channel
					fusionImage1 [nIdx + CHANNEL_B] = red11 * green11 * blue11;
					fusionImage2 [nIdx + CHANNEL_B] = red22 * green22 * blue22;
				}//end y
			}//end x
		}//measure Exposure


		// apply the strength dials
		//the total of all strength dials cannot exceed 1, the 3-way weber function resolves this issue by automatically adjusting all dials
		// so that the totals do not exceed 1.   If you take 1 strength dial and force it to 1, then it will dial back to .9 and the other two will be .1
		// if any two dials are set the exact same, one will adjust .01 and the other will adjust -.01, so that none of the dials are the exact same
		// this next routine will multiply the current pixel value against the strenght dials, so that the total sum of all pixel do not exceed 1.0

		/*
		char sBuffer6[400];
		float totalValue = contrast + saturation + exposure;

		sprintf(sBuffer6,"contrast = %f\n saturation = %f\n Exposure = %f\n\n totalValue = %f"
			             ,contrast,       saturation,       exposure,         totalValue);
		MessageBox(NULL,sBuffer6,"Dial Values", MB_OK);*/

		for (int x = 0; x < nWidth; x++)
		{
			for (int y = 0; y < nHeight; y++)
			{
				int nIdx = x * 4 + y * 4 * nWidth;

				// Array is now CSE
				// meaning Contrast Saturation Exposure
				float cseContrast1 = fusionImage1[nIdx + CHANNEL_R] * contrast;
				float cseSaturation1 = fusionImage1[nIdx + CHANNEL_G] * saturation;
				float cseExposure1 = fusionImage1[nIdx + CHANNEL_B] * exposure;

				float cseContrast2 = fusionImage2[nIdx + CHANNEL_R] * contrast;
				float cseSaturation2 = fusionImage2[nIdx + CHANNEL_G] * saturation;
				float cseExposure2 = fusionImage2[nIdx + CHANNEL_B] * exposure;

				fusionImage1[nIdx + CHANNEL_R] = cseContrast1;
				fusionImage1[nIdx + CHANNEL_G] = cseSaturation1;
				fusionImage1[nIdx + CHANNEL_B] = cseExposure1;

				fusionImage2[nIdx + CHANNEL_R] = cseContrast2;
				fusionImage2[nIdx + CHANNEL_G] = cseSaturation2;
				fusionImage2[nIdx + CHANNEL_B] = cseExposure2;
			}
		}



					
		// Alpha Mask test			
		for (int x = 0; x < nWidth; x++)
		{
			for (int y = 0; y < nHeight; y++)
			{				
				int nIdx = x * 4 + y * 4 * nWidth;

				float enhancedRed = 0;
				float enhancedGreen = 0;
				float enhancedBlue = 0;

				if (topBottom == 0)
				{
					if (channel == 0)
					{
						enhancedRed = fusionImage1[nIdx + CHANNEL_R];
						enhancedGreen = fusionImage1[nIdx + CHANNEL_R];
						enhancedBlue = fusionImage1[nIdx + CHANNEL_R];
					}

					if (channel == 1)
					{
						enhancedRed = fusionImage1[nIdx + CHANNEL_G];
						enhancedGreen = fusionImage1[nIdx + CHANNEL_G];
						enhancedBlue = fusionImage1[nIdx + CHANNEL_G];
					}

					if (channel == 2)
					{
						enhancedRed = fusionImage1[nIdx + CHANNEL_B];
						enhancedGreen = fusionImage1[nIdx + CHANNEL_B];
						enhancedBlue = fusionImage1[nIdx + CHANNEL_B];
					}
				}

				if (topBottom == 1)
				{
					if (channel == 0)
					{
						enhancedRed = fusionImage2[nIdx + CHANNEL_R];
						enhancedGreen = fusionImage2[nIdx + CHANNEL_R];
						enhancedBlue = fusionImage2[nIdx + CHANNEL_R];
					}

					if (channel == 1)
					{
						enhancedRed = fusionImage2[nIdx + CHANNEL_G];
						enhancedGreen = fusionImage2[nIdx + CHANNEL_G];
						enhancedBlue = fusionImage2[nIdx + CHANNEL_G];
					}

					if (channel == 2)
					{
						enhancedRed = fusionImage2[nIdx + CHANNEL_B];
						enhancedGreen = fusionImage2[nIdx + CHANNEL_B];
						enhancedBlue = fusionImage2[nIdx + CHANNEL_B];
					}
				}

				pBGRA_out[nIdx + CHANNEL_R] = CLAMP255(enhancedRed * colorDepth);
				pBGRA_out[nIdx + CHANNEL_G] = CLAMP255(enhancedGreen * colorDepth);
				pBGRA_out[nIdx + CHANNEL_B] = CLAMP255(enhancedBlue * colorDepth);
			}
		}


		delete [] inputImage1;
		delete [] inputImage2;


		float* outputImage=new float[nWidth * nHeight * 4];
		initalizeArrayNeutralGrey(outputImage, nWidth, nHeight);


		delete [] fusionImage1;
		delete [] fusionImage2;

		//copyImage(saturatedImage, nWidth, nHeight, outputImage, nWidth, nHeight);
		//copy image 1 to saturatedImage so we may have image data
		for (int x = 0; x < nWidth; x++)		
		{
			for (int y = 0; y < nHeight; y++)
			{
				//int nIdx = x * 4 + y * 4 * nWidth;

				//float red = saturatedImage[nIdx + CHANNEL_R];
				//float green = saturatedImage[nIdx + CHANNEL_G];
				//float blue = saturatedImage[nIdx + CHANNEL_B];

				//outputImage[nIdx + CHANNEL_R] = red;
				//outputImage[nIdx + CHANNEL_G] = green;
				//outputImage[nIdx + CHANNEL_B] = blue;
			}
		}


		//delete the luminance1 and luminance 2
		delete [] luma1;
		delete [] luma2;


		// output
		for (int x = 0; x < nWidth; x++)
		{
			for (int y = 0; y < nHeight; y++)
			{				
				//int nIdx = x * 4 + y * 4 * nWidth;
				
				//float enhancedRed = inputImage1[nIdx+CHANNEL_R] * colorDepth;
				//float enhancedGreen = inputImage1[nIdx+CHANNEL_G] * colorDepth;
				//float enhancedBlue = inputImage1[nIdx+CHANNEL_B] * colorDepth;

				//pBGRA_out[nIdx+CHANNEL_R] = CLAMP255(enhancedRed);
				//pBGRA_out[nIdx+CHANNEL_G] = CLAMP255(enhancedGreen);
				//pBGRA_out[nIdx+CHANNEL_B] = CLAMP255(enhancedBlue);
			}
		}
		



		delete [] outputImage;
	}



	//*****************Drawing functions for the BOX *********************************
	//how is the drawing handled
	//DRAW_AUTOMATICALLY	the main program will fully take care of this and draw a box, title, socket and thumbnail
	//DRAW_SIMPLE_A			will draw a box, title and sockets and call CustomDraw
	//DRAW_SIMPLE_B			will draw a box and sockets and call CustomDraw
	//DRAW_SOCKETSONLY      will call CustomDraw and then draw sockets on top of it
	
	// highlighting rectangle around is always drawn except for DRAW_SOCKETSONLY

	virtual int GetDrawingType ()
	{
		int nType = DRAW_AUTOMATICALLY;

		return nType;

	}


	// Custom Drawing
	// custom drawing function called when drawing type is different than DRAW_AUTOMATICALLY
	// it is not always in real pixels but scaled depending on where it is drawn
	// the scale could be from 1.0 to > 1.0
	// so you always multiply the position, sizes, font size, line width with the scale	
	virtual void CustomDraw (HDC hDC, int nX,int nY, int nWidth, int nHeight, float scale, BOOL bIsHighlighted, UIParameters* pParameters)
	{




	}





	//************ Optional Functions *****************************************************************************************
	// those functions are not necessary for normal effect, they are mostly for special effects and objects


	// Called when FLAG_HELPER set. 
	// When UI data changed (user turned knob) this function will be called as soon as user finish channging the data
	// You will get the latest parameters and also which parameter changed
	// Normally for effects you don't have to do anything here because you will get the same parameters in the process function
	// It is only for helper objects that may not go to Process Data 
	BOOL UIParametersChanged (UIParameters* pParameters, int nParameter)
	{
		return FALSE;
	}

	// when button is pressed on UI, this function will be called with the parameter and sub button (for multi button line)
	BOOL UIButtonPushed (int nParam, int nSubButton, UIParameters* pParameters)
	{
		return TRUE;
	}

	// Called when FLAG_NEEDSIZEDATA set
	// Called before each calculation (Process_Data)
	// If your process depends on a position on a frame you may need the data to correctly display it because Process_Data receives only a preview crop
	// Most normal effects don't depend on the position in frame so you don't need the data
	// Example: drawing a circle at a certain position requires to know what is displayed in preview or the circle will be at the same size and position regardless of zoom
	
	// Note: Even if you need position but you don't want to mess with the crop data, just ignore it and pretend the Process_Data are always of full image (they are not). 
	// In worst case this affects only preview when using zoom. The full process image always sends the whole data

	// nOriginalW, nOriginalH - the size of the original - full image. If user sets Resize on input - this will be the resized image
	// nPreviewW, nPreviewH   - this is the currently processed preview width/height - it is the same that Process_Data will receive
	//                        - in full process the nPreviewW, nPreviewH is equal nOriginalW, nOriginalH
	// Crop X1,Y1,X2,Y2       - relative coordinates of preview crop rectangle in <0...1>, for full process they are 0,0,1,1 (full rectangle)	
	// dZoom                  - Zoom of the Preview, for full process the dZoom = 1.0
	void SetSizeData(int nOriginalW, int nOriginalH, int nPreviewW, int nPreviewH, double dCropX1, double dCropY1, double dCropX2, double dCropY2, double dZoom)
	{

		// so if you need the position and zoom, this is the place to get it.
		// Note: because of IBM wisdom the internal bitmaps are on PC always upside down, but the coordinates are not
		// which you  need to take into account. See rectangle demo project for more info 


	}


	// ***** Mouse handling on workplace *************************** 
	// only if FLAG_NEEDMOUSE is set
	//****************************************************************
	//this is for special objects that need to receive mouse, like a knob or slider on workplace
	// normally you use this for FLAG_BINDING objects

	// in coordinates relative to top, left corner of the object (0,0)
	virtual BOOL MouseButtonDown (int nX, int nY, int nWidth, int nHeight, UIParameters* pParameters)
	{
		// return FALSE if not handled
		// return TRUE if handled
		return FALSE;
	}

	// in coordinates relative to top, left corner of the object (0,0)
	virtual BOOL MouseMove (int nX, int nY, int nWidth, int nHeight, UIParameters* pParameters)
	{
		return FALSE;
	}
	
	// in coordinates relative to top, left corner of the object (0,0)
	virtual BOOL MouseButtonUp (int nX, int nY, int nWidth, int nHeight, UIParameters* pParameters)
	{
		
		// Note: if we changed data and need to recalculate the flow we need to return TRUE


		// return FALSE if not handled
		// return TRUE if handled
		
		return TRUE;
	}


};

extern "C"
{
	// Plugin factory function
	__declspec(dllexport) IPlugin* Create_Plugin ()
	{
		//allocate a new object and return it
		return new PluginTest ();
	}
	
	// Plugin cleanup function
	__declspec(dllexport) void Release_Plugin (IPlugin* p_plugin)
	{
		//we allocated in the factory with new, delete the passed object
		delete p_plugin;
	}
	
}


// this is the name that will appear in the object library
extern "C" __declspec(dllexport) char* GetPluginName()
{
	return "! A Andy's Exposure Fusion";
}


// This MUST be unique string for each plugin so we can save the data

extern "C" __declspec(dllexport) char* GetPluginID()
{
	
// 	IMPORTANT:you have to fill unique ID for every plugin:
// 	The ID must be unique or loading and saving will not be able to find correct plugin
//  Comment out this line below so you can compile
//	ATTENTION

	return "com.lumafilters.Exposure.Fusion";
	
}


// category of plugin, for now the EFFECT go to top library box, everything else goes to the middle library box
extern "C" __declspec(dllexport) int GetCategory()
{
		
	return CATEGORY_BUILDING_BLOCK;
	
}